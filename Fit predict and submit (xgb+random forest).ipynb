{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit, predict and submit (xgb+random forest)\n",
    "\n",
    "In this notebook I use the Extreme Gradient Boosting to make my predictions. This notebook also includes the tuning the xgb classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valentin/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1035: UserWarning: Duplicate key in file \"/Users/valentin/anaconda/lib/python2.7/site-packages/matplotlib/mpl-data/matplotlibrc\", line #513\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import matplotlib \n",
    "import numpy as np\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk \n",
    "\n",
    "from dateutil import parser\n",
    "\n",
    "import pyprind\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", palette=\"muted\")\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score,log_loss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def normalize(df, features):\n",
    "    for k in features:\n",
    "        df[k] = preprocessing.MinMaxScaler().fit_transform(df[k])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 features\n",
      "['Minute', 'Hour', 'isNotIntact', 'Day', 'Age', 'Month', 'AgeInYears', 'HasName', 'AgeInMonths', 'BreedScore', 'isFemale', 'AgeInWeeks', 'isCat', 'Color=Black', 'Color=White', 'ColorCount', 'Breed=Domestic Shorthair', 'Color=Brown', 'isMix', 'Color=Tan', 'Breed=Pit Bull', 'Color=Blue', 'Breed=Chihuahua Shorthair', 'BreedCount', 'Color=Red', 'Breed=Labrador Retriever', 'Color=Brown Tabby', 'Color=Brown Brindle', 'Color=Tricolor', 'Breed=German Shepherd']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minute</th>\n",
       "      <th>Hour</th>\n",
       "      <th>isNotIntact</th>\n",
       "      <th>Day</th>\n",
       "      <th>Age</th>\n",
       "      <th>Month</th>\n",
       "      <th>AgeInYears</th>\n",
       "      <th>HasName</th>\n",
       "      <th>AgeInMonths</th>\n",
       "      <th>BreedScore</th>\n",
       "      <th>...</th>\n",
       "      <th>Breed=Pit Bull</th>\n",
       "      <th>Color=Blue</th>\n",
       "      <th>Breed=Chihuahua Shorthair</th>\n",
       "      <th>BreedCount</th>\n",
       "      <th>Color=Red</th>\n",
       "      <th>Breed=Labrador Retriever</th>\n",
       "      <th>Color=Brown Tabby</th>\n",
       "      <th>Color=Brown Brindle</th>\n",
       "      <th>Color=Tricolor</th>\n",
       "      <th>Breed=German Shepherd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>365</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Minute  Hour  isNotIntact  Day  Age  Month  AgeInYears  HasName  \\\n",
       "0      22    18            1   12  365      2           1        1   \n",
       "1      44    12            1   13  365     10           1        1   \n",
       "2      28    12            1   31  730      1           2        1   \n",
       "\n",
       "   AgeInMonths  BreedScore          ...            Breed=Pit Bull  Color=Blue  \\\n",
       "0            0    0.857143          ...                         0           0   \n",
       "1            0    0.823529          ...                         0           0   \n",
       "2            0    0.000000          ...                         1           1   \n",
       "\n",
       "   Breed=Chihuahua Shorthair  BreedCount  Color=Red  Breed=Labrador Retriever  \\\n",
       "0                          0           1          0                         0   \n",
       "1                          0           1          0                         0   \n",
       "2                          0           1          0                         0   \n",
       "\n",
       "   Color=Brown Tabby  Color=Brown Brindle  Color=Tricolor  \\\n",
       "0                  0                    0               0   \n",
       "1                  0                    0               0   \n",
       "2                  0                    0               0   \n",
       "\n",
       "   Breed=German Shepherd  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('preprocessing_train_3.csv')\n",
    "df_test = pd.read_csv('preprocessing_test_3.csv')\n",
    "features = list(pd.read_csv('features.csv')['0'])\n",
    "#features = list(set(df_train.columns.values).intersection(df_test.columns.values))\n",
    "print str(len(features)) + ' features'\n",
    "print features\n",
    "\n",
    "destinies = list(set(df_train['OutcomeType']))\n",
    "labelEncoderDestinies = preprocessing.LabelEncoder()\n",
    "labelEncoderDestinies.fit(destinies)\n",
    "\n",
    "for d in destinies:\n",
    "    df_train[d] = df_train['OutcomeType'].map(lambda x: int(x==d) )\n",
    "df_train[features][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Minute', 'Hour', 'isNotIntact', 'Day', 'Age', 'Month', 'AgeInYears', 'HasName', 'AgeInMonths', 'BreedScore', 'isFemale', 'AgeInWeeks', 'isCat', 'ColorCount', 'isMix', 'BreedCount']\n"
     ]
    }
   ],
   "source": [
    "print[f for f in features if 'Color=' not in f and 'Breed=' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 features\n",
      "21383 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare the data for XGB\n",
    "# normalize\n",
    "df_train = normalize(df_train, features)\n",
    "df_test = normalize(df_test, features)\n",
    "target = destinies\n",
    "predicators = features\n",
    "\n",
    "df_train['type'] = df_train['OutcomeType'].map( labelEncoderDestinies.transform )\n",
    "y = df_train['type']\n",
    "X = df_train[features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print str(X_train.shape[1]) + ' features'\n",
    "print str(X_train.shape[0]) + ' rows\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quick evaluation of the model\n",
    "train_X = X_train.values\n",
    "train_Y = y_train.values\n",
    "\n",
    "test_X = X_test.values\n",
    "test_Y = y_test.values\n",
    "\n",
    "xg_train = xgb.DMatrix( train_X, label=train_Y)\n",
    "xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "param['objective'] = 'multi:softprob'\n",
    "param['eta'] = 0.12\n",
    "param['max_depth'] = 8\n",
    "param['min_child_weight'] = 3\n",
    "param['silent'] = 1\n",
    "param['gamma'] = 0.5\n",
    "param['seed'] = 44\n",
    "param['alpha'] = 0.001\n",
    "param['lambda'] = 5\n",
    "param['num_class'] = len(destinies)\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 100\n",
    "param['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(param, xg_train, num_round )#, watchlist );\n",
    "yprob = bst.predict( xg_test ).reshape( test_Y.shape[0], len(destinies) )\n",
    "ylabelpred = np.argmax(yprob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5346\n",
      "predicting, classification precision=0.689862\n"
     ]
    }
   ],
   "source": [
    "print len(ylabelpred)\n",
    "print ('predicting, classification precision=%f' % (1 - sum( int(ylabelpred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tuning\n",
    "## Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 3 min_child_weight: 1 seed:  0 1 2 score: 0.680259383963\n",
      "max_depth: 3 min_child_weight: 3 seed:  0 1 2 score: 0.679760568649\n",
      "max_depth: 3 min_child_weight: 5 seed:  0 1 2 score: 0.68050879162\n",
      "max_depth: 5 min_child_weight: 1 seed:  0 1 2 score: 0.683189923931\n",
      "max_depth: 5 min_child_weight: 3 seed:  0 1 2 score: 0.684436962215\n",
      "max_depth: 5 min_child_weight: 5 seed:  0 1 2 score: 0.681755829904\n",
      "max_depth: 7 min_child_weight: 1 seed:  0 1 2 score: 0.683938146901\n",
      "max_depth: 7 min_child_weight: 3 seed:  0 1 2 score: 0.683751091158\n",
      "max_depth: 7 min_child_weight: 5 seed:  0 1 2 score: 0.68555929667\n",
      "max_depth: 9 min_child_weight: 1 seed:  0 1 2 score: 0.685871056241\n",
      "max_depth: 9 min_child_weight: 3 seed:  0 1 2 score: 0.686681631126\n",
      "max_depth: 9 min_child_weight: 5 seed:  0 1 2 score: 0.685309889014\n"
     ]
    }
   ],
   "source": [
    "max_depths = range(3,10,2)\n",
    "min_child_weights = range(1,6,2)\n",
    "results = []\n",
    "for depth in max_depths:\n",
    "    for child_weight in min_child_weights:\n",
    "        print \"max_depth: \" + str(depth),\n",
    "        print \"min_child_weight: \" + str(child_weight),\n",
    "        print \"seed: \",\n",
    "        scores = []\n",
    "        for i in range(3):\n",
    "            print i,\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = i)\n",
    "            train_X = X_train.values\n",
    "            train_Y = y_train.values\n",
    "            test_X = X_test.values\n",
    "            test_Y = y_test.values\n",
    "            xg_train = xgb.DMatrix( train_X, label=train_Y)\n",
    "            xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "            # setup parameters for xgboost\n",
    "            param = {}\n",
    "            # use softprob multi-class classification\n",
    "            param['objective'] = 'multi:softprob'\n",
    "            # scale weight of positive examples\n",
    "            param['eta'] = 0.2\n",
    "            param['max_depth'] = depth\n",
    "            param['min_child_weight'] = child_weight\n",
    "            param['silent'] = 1\n",
    "            param['gamma'] = 0\n",
    "            param['seed'] = 44\n",
    "            param['num_class'] = len(destinies)\n",
    "            watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "            num_round = 100\n",
    "            # do the same thing again, but output probabilities\n",
    "            param['objective'] = 'multi:softprob'\n",
    "            bst = xgb.train(param, xg_train, num_round) #, watchlist );\n",
    "            yprob = bst.predict( xg_test ).reshape( test_Y.shape[0], len(destinies) )\n",
    "            ylabelpred = np.argmax(yprob, axis=1)\n",
    "            score = ((1 - sum( int(ylabelpred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))\n",
    "            scores.append(score)\n",
    "        print \"score:\",\n",
    "        print np.mean(scores)\n",
    "        results.append( {'score' : np.mean(scores) , 'scores' : scores, 'max_depth' : depth, 'min_child_weight' :  child_weight } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.68668163112607561, 'max_depth': 9, 'min_child_weight': 3, 'scores': [0.6835016835016835, 0.69248035914702588, 0.68406285072951745]}\n",
      "{'score': 0.68587105624142664, 'max_depth': 9, 'min_child_weight': 1, 'scores': [0.68163112607557053, 0.69117096894874674, 0.68481107369996264]}\n",
      "{'score': 0.68555929667040783, 'max_depth': 7, 'min_child_weight': 5, 'scores': [0.68499812944257388, 0.69322858211747107, 0.67845117845117842]}\n"
     ]
    }
   ],
   "source": [
    "for r in sorted( results , key = lambda x : np.mean(x['score']) , reverse = True)[:3]:\n",
    "    #r ['score'] = np.mean(r['score'])\n",
    "    print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best: 8,5\n",
    "\n",
    "## Tune gamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.0 seed:  0 1 2 score: 0.686245167727\n",
      "gamma: 0.01 seed:  0 1 2 score: 0.683439331587\n",
      "gamma: 0.02 seed:  0 1 2 score: 0.68287816436\n",
      "gamma: 0.03 seed:  0 1 2 score: 0.684686369872\n",
      "gamma: 0.04 seed:  0 1 2 score: 0.682316997132\n"
     ]
    }
   ],
   "source": [
    "gammas = [i/100.0 for i in range(0,5)]\n",
    "results = []\n",
    "for gamma in gammas:\n",
    "    print \"gamma: \" + str(gamma),\n",
    "    print \"seed: \",\n",
    "    scores = []\n",
    "    for i in range(3):\n",
    "        print i,\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = i)\n",
    "        train_X = X_train.values\n",
    "        train_Y = y_train.values\n",
    "        test_X = X_test.values\n",
    "        test_Y = y_test.values\n",
    "        xg_train = xgb.DMatrix( train_X, label=train_Y)\n",
    "        xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "        # setup parameters for xgboost\n",
    "        param = {}\n",
    "        # use softprob multi-class classification\n",
    "        param['objective'] = 'multi:softprob'\n",
    "        # scale weight of positive examples\n",
    "        param['eta'] = 0.2\n",
    "        param['max_depth'] = 8\n",
    "        param['min_child_weight'] = 5\n",
    "        param['silent'] = 1\n",
    "        param['gamma'] = gamma\n",
    "        param['seed'] = 44\n",
    "        param['num_class'] = len(destinies)\n",
    "\n",
    "        watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "        num_round = 100\n",
    "        # do the same thing again, but output probabilities\n",
    "        param['objective'] = 'multi:softprob'\n",
    "        bst = xgb.train(param, xg_train, num_round) #, watchlist );\n",
    "        yprob = bst.predict( xg_test ).reshape( test_Y.shape[0], len(destinies) )\n",
    "        ylabelpred = np.argmax(yprob, axis=1)\n",
    "        score = ((1 - sum( int(ylabelpred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))\n",
    "        scores.append(score)\n",
    "    print \"score:\",\n",
    "    print np.mean(scores)\n",
    "    results.append( {'score' : np.mean(scores) , 'scores' : scores, 'gamma' : gamma} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma best values: 0\n",
    "\n",
    "## tune alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1e-05 seed:  0 1 2 score: 0.686245167727\n",
      "alpha: 0.01 seed:  0 1 2 score: 0.68287816436\n",
      "alpha: 0.1 seed:  0 1 2 score: 0.683002868188\n",
      "alpha: 1 seed:  0 1 2 score: 0.683314627759\n",
      "alpha: 100 seed:  0 1 2 score: 0.674211248285\n"
     ]
    }
   ],
   "source": [
    "alphas = [1e-5, 1e-2, 0.1, 1, 100]\n",
    "results = []\n",
    "for alpha in alphas:\n",
    "    print \"alpha: \" + str(alpha),\n",
    "    print \"seed: \",\n",
    "    scores = []\n",
    "    for i in range(3):\n",
    "        print i,\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = i)\n",
    "        train_X = X_train.values\n",
    "        train_Y = y_train.values\n",
    "        test_X = X_test.values\n",
    "        test_Y = y_test.values\n",
    "        xg_train = xgb.DMatrix( train_X, label=train_Y)\n",
    "        xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "        # setup parameters for xgboost\n",
    "        param = {}\n",
    "        # use softprob multi-class classification\n",
    "        param['objective'] = 'multi:softprob'\n",
    "        # scale weight of positive examples\n",
    "        param['eta'] = 0.2\n",
    "        param['max_depth'] = 8\n",
    "        param['min_child_weight'] = 5\n",
    "        param['silent'] = 1\n",
    "        param['gamma'] = 0\n",
    "        param['alpha'] = alpha\n",
    "        param['seed'] = 44\n",
    "        param['num_class'] = len(destinies)\n",
    "\n",
    "        watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "        num_round = 100\n",
    "        # do the same thing again, but output probabilities\n",
    "        param['objective'] = 'multi:softprob'\n",
    "        bst = xgb.train(param, xg_train, num_round) #, watchlist );\n",
    "        yprob = bst.predict( xg_test ).reshape( test_Y.shape[0], len(destinies) )\n",
    "        ylabelpred = np.argmax(yprob, axis=1)\n",
    "        score = ((1 - sum( int(ylabelpred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))\n",
    "        scores.append(score)\n",
    "    print \"score:\",\n",
    "    print np.mean(scores)\n",
    "    results.append( {'score' : np.mean(scores) , 'scores' : scores, 'alpha' : alpha} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05, 'score': 0.68624516772664912, 'scores': [0.68593340815563031, 0.69191919191919193, 0.68088290310512534]}\n",
      "{'alpha': 1, 'score': 0.68331462775907215, 'scores': [0.68911335578002242, 0.68555929667040783, 0.67527123082678631]}\n",
      "{'alpha': 0.1, 'score': 0.68300286818805345, 'scores': [0.68275346053123831, 0.68761690983913204, 0.67863823419378977]}\n"
     ]
    }
   ],
   "source": [
    "for r in sorted( results , key = lambda x : np.mean(x['score']) , reverse = True)[:3]:\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1e-06 seed:  0 1 2 score: 0.686245167727\n",
      "alpha: 1e-05 seed:  0 1 2 score: 0.686245167727\n",
      "alpha: 0.0001 seed:  0 1 2 score: 0.684374610301\n",
      "alpha: 0.001 seed:  0 1 2 score: 0.68244170096\n"
     ]
    }
   ],
   "source": [
    "alphas = [1e-6, 1e-5, 1e-4,1e-3]\n",
    "results = []\n",
    "for alpha in alphas:\n",
    "    print \"alpha: \" + str(alpha),\n",
    "    print \"seed: \",\n",
    "    scores = []\n",
    "    for i in range(3):\n",
    "        print i,\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = i)\n",
    "        train_X = X_train.values\n",
    "        train_Y = y_train.values\n",
    "        test_X = X_test.values\n",
    "        test_Y = y_test.values\n",
    "        xg_train = xgb.DMatrix( train_X, label=train_Y)\n",
    "        xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "        # setup parameters for xgboost\n",
    "        param = {}\n",
    "        # use softprob multi-class classification\n",
    "        param['objective'] = 'multi:softprob'\n",
    "        # scale weight of positive examples\n",
    "        param['eta'] = 0.2\n",
    "        param['max_depth'] = 8\n",
    "        param['min_child_weight'] = 5\n",
    "        param['silent'] = 1\n",
    "        param['gamma'] = 0\n",
    "        param['alpha'] = alpha\n",
    "        param['seed'] = 44\n",
    "        param['num_class'] = len(destinies)\n",
    "\n",
    "        watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "        num_round = 100\n",
    "        # do the same thing again, but output probabilities\n",
    "        param['objective'] = 'multi:softprob'\n",
    "        bst = xgb.train(param, xg_train, num_round) #, watchlist );\n",
    "        yprob = bst.predict( xg_test ).reshape( test_Y.shape[0], len(destinies) )\n",
    "        ylabelpred = np.argmax(yprob, axis=1)\n",
    "        score = ((1 - sum( int(ylabelpred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))\n",
    "        scores.append(score)\n",
    "    print \"score:\",\n",
    "    print np.mean(scores)\n",
    "    results.append( {'score' : np.mean(scores) , 'scores' : scores, 'alpha' : alpha} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-06, 'score': 0.68624516772664912, 'scores': [0.68593340815563031, 0.69191919191919193, 0.68088290310512534]}\n",
      "{'alpha': 1e-05, 'score': 0.68624516772664912, 'scores': [0.68593340815563031, 0.69191919191919193, 0.68088290310512534]}\n",
      "{'alpha': 0.0001, 'score': 0.68437461030053626, 'scores': [0.68368873924429474, 0.6909839132061355, 0.67845117845117842]}\n"
     ]
    }
   ],
   "source": [
    "for r in sorted( results , key = lambda x : np.mean(x['score']) , reverse = True)[:3]:\n",
    "    print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the same process to find the best values for eta (learning rate, lambda and the number of steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# train on the whole dataset, predict and ouput\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "## xgb only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 0 ..., 0 4 4]\n"
     ]
    }
   ],
   "source": [
    "train_X = df_train[features].values\n",
    "train_Y = df_train['OutcomeType'].map( labelEncoderDestinies.transform ).values\n",
    "\n",
    "print train_Y\n",
    "\n",
    "test_X = df_test[features].values\n",
    "\n",
    "xg_train = xgb.DMatrix( train_X, label=train_Y)\n",
    "xg_test = xgb.DMatrix(test_X)\n",
    "\n",
    "param = {}\n",
    "param['objective'] = 'multi:softprob'\n",
    "param['eta'] = 0.12\n",
    "param['max_depth'] = 8\n",
    "param['min_child_weight'] = 3\n",
    "param['silent'] = 1\n",
    "param['gamma'] = 0.5\n",
    "param['seed'] = 44\n",
    "param['alpha'] = 0.001\n",
    "param['lambda'] = 5\n",
    "param['num_class'] = len(destinies)\n",
    "\n",
    "watchlist = [ (xg_train,'train')]\n",
    "num_round = 100\n",
    "param['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(param, xg_train, num_round )\n",
    "yprob = bst.predict( xg_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026166</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>0.145059</td>\n",
       "      <td>0.807049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.709248</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.205729</td>\n",
       "      <td>0.076040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.441760</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.012202</td>\n",
       "      <td>0.216957</td>\n",
       "      <td>0.324679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.241882</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>0.428157</td>\n",
       "      <td>0.297572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.367302</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.012561</td>\n",
       "      <td>0.529992</td>\n",
       "      <td>0.089062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.116060</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.706597</td>\n",
       "      <td>0.161815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.117947</td>\n",
       "      <td>0.085590</td>\n",
       "      <td>0.579883</td>\n",
       "      <td>0.169116</td>\n",
       "      <td>0.047465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.857592</td>\n",
       "      <td>0.024291</td>\n",
       "      <td>0.009626</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.093808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.829638</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.135161</td>\n",
       "      <td>0.032179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.564258</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>0.326636</td>\n",
       "      <td>0.077836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Adoption      Died  Euthanasia  Return_to_owner  Transfer\n",
       "1   0.026166  0.002763    0.018962         0.145059  0.807049\n",
       "2   0.709248  0.000920    0.008063         0.205729  0.076040\n",
       "3   0.441760  0.004402    0.012202         0.216957  0.324679\n",
       "4   0.241882  0.005386    0.027004         0.428157  0.297572\n",
       "5   0.367302  0.001082    0.012561         0.529992  0.089062\n",
       "6   0.116060  0.001162    0.014366         0.706597  0.161815\n",
       "7   0.117947  0.085590    0.579883         0.169116  0.047465\n",
       "8   0.857592  0.024291    0.009626         0.014682  0.093808\n",
       "9   0.829638  0.001015    0.002007         0.135161  0.032179\n",
       "10  0.564258  0.000849    0.030421         0.326636  0.077836"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_xgb = pd.DataFrame(yprob, columns=['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer'])\n",
    "output_xgb.index += 1\n",
    "output_xgb.to_csv('submission27-xgboost-tuned+breed-score+feature-selection.csv', index_label='ID')\n",
    "output_xgb[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using multiple classifiers\n",
    "\n",
    "##### Averaging\n",
    "\n",
    "I simply use the average of two classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, random_state=12, min_samples_split = 3, min_samples_leaf = 2, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=2, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=4,\n",
       "            oob_score=False, random_state=12, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train[\"OutcomeType\"]\n",
    "X = df_train[features]\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = df_test[features]\n",
    "pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094098</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.041184</td>\n",
       "      <td>0.217397</td>\n",
       "      <td>0.645415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.592110</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.021890</td>\n",
       "      <td>0.286058</td>\n",
       "      <td>0.099091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.413942</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.022840</td>\n",
       "      <td>0.184525</td>\n",
       "      <td>0.378416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.215565</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.086486</td>\n",
       "      <td>0.314288</td>\n",
       "      <td>0.380328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.415659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.412464</td>\n",
       "      <td>0.150458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.212099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023368</td>\n",
       "      <td>0.626274</td>\n",
       "      <td>0.138259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.281319</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.289633</td>\n",
       "      <td>0.235879</td>\n",
       "      <td>0.185478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.684767</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>0.259541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.806109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086553</td>\n",
       "      <td>0.107339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.501351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>0.338271</td>\n",
       "      <td>0.083048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Adoption      Died  Euthanasia  Return_to_owner  Transfer\n",
       "1   0.094098  0.001905    0.041184         0.217397  0.645415\n",
       "2   0.592110  0.000851    0.021890         0.286058  0.099091\n",
       "3   0.413942  0.000277    0.022840         0.184525  0.378416\n",
       "4   0.215565  0.003333    0.086486         0.314288  0.380328\n",
       "5   0.415659  0.000000    0.021419         0.412464  0.150458\n",
       "6   0.212099  0.000000    0.023368         0.626274  0.138259\n",
       "7   0.281319  0.007690    0.289633         0.235879  0.185478\n",
       "8   0.684767  0.006091    0.014948         0.034653  0.259541\n",
       "9   0.806109  0.000000    0.000000         0.086553  0.107339\n",
       "10  0.501351  0.000000    0.077330         0.338271  0.083048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rf = pd.DataFrame(pred, columns=['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer'])\n",
    "output_rf.index += 1\n",
    "output_rf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060132</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.181228</td>\n",
       "      <td>0.726232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.650679</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.014976</td>\n",
       "      <td>0.245894</td>\n",
       "      <td>0.087566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.427851</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>0.200741</td>\n",
       "      <td>0.351547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.228723</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>0.056745</td>\n",
       "      <td>0.371222</td>\n",
       "      <td>0.338950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.391481</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.016990</td>\n",
       "      <td>0.471228</td>\n",
       "      <td>0.119760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.164079</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.018867</td>\n",
       "      <td>0.666436</td>\n",
       "      <td>0.150037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.199633</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>0.434758</td>\n",
       "      <td>0.202498</td>\n",
       "      <td>0.116472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.771180</td>\n",
       "      <td>0.015191</td>\n",
       "      <td>0.012287</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>0.176675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.817873</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.110857</td>\n",
       "      <td>0.069759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.532805</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.053876</td>\n",
       "      <td>0.332453</td>\n",
       "      <td>0.080442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Adoption      Died  Euthanasia  Return_to_owner  Transfer\n",
       "1   0.060132  0.002334    0.030073         0.181228  0.726232\n",
       "2   0.650679  0.000885    0.014976         0.245894  0.087566\n",
       "3   0.427851  0.002340    0.017521         0.200741  0.351547\n",
       "4   0.228723  0.004360    0.056745         0.371222  0.338950\n",
       "5   0.391481  0.000541    0.016990         0.471228  0.119760\n",
       "6   0.164079  0.000581    0.018867         0.666436  0.150037\n",
       "7   0.199633  0.046640    0.434758         0.202498  0.116472\n",
       "8   0.771180  0.015191    0.012287         0.024667  0.176675\n",
       "9   0.817873  0.000507    0.001004         0.110857  0.069759\n",
       "10  0.532805  0.000424    0.053876         0.332453  0.080442"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting = 0.5 * (pred + yprob)\n",
    "output_rf = pd.DataFrame(voting, columns=['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer'])\n",
    "output_rf.index += 1\n",
    "output_rf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_rf.to_csv('submission28-xgboost-tuned+tuned-random_forest+feature-selec.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_clf1 = xgb.XGBClassifier(objective ='multi:softprob', learning_rate = 0.1, max_depth=8,\\\n",
    "                           min_child_weight=3,gamma=0.5,seed=44,reg_alpha=0.001,reg_lambda=5, n_estimators=100)\n",
    "rdf_clf1 = RandomForestClassifier(n_estimators=300, random_state=12, min_samples_split = 3, min_samples_leaf = 2, n_jobs=4)\n",
    "rdf_clf2 = RandomForestClassifier(criterion = 'entropy', n_estimators=300, random_state=65, min_samples_split = 3, min_samples_leaf = 2, n_jobs=4)\n",
    "model = VotingClassifier(estimators=[('xgb1', xgb_clf1) ,('rdf1', rdf_clf1),('rdf2', rdf_clf2) ], voting='soft')\n",
    "#model = rdf_clf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 features\n",
      "21383 rows\n",
      "\n",
      "Fitting...\n",
      "\n",
      "Predicting...\n",
      "\n",
      "0.686494575383  accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = normalize(df_train, features)\n",
    "df_test = normalize(df_test, features)\n",
    "y = df_train[\"OutcomeType\"]\n",
    "features_selected = features[:]\n",
    "X = df_train[features_selected]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "#model =  RandomForestClassifier(n_estimators=500, random_state=12)\n",
    "print str(X_train.shape[1]) + ' features'\n",
    "print str(X_train.shape[0]) + ' rows\\n'\n",
    "print 'Fitting...\\n'\n",
    "model.fit(X_train, y_train)\n",
    "print 'Predicting...\\n'\n",
    "y_pred = model.predict(X_test)\n",
    "print accuracy_score(y_test, y_pred), ' accuracy.\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train, Fit, submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_train[\"OutcomeType\"]\n",
    "X = df_train[features]\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "X_test = df_test[features]\n",
    "pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072526</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.039508</td>\n",
       "      <td>0.191886</td>\n",
       "      <td>0.692908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.641971</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.019447</td>\n",
       "      <td>0.258328</td>\n",
       "      <td>0.079332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.424993</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.199556</td>\n",
       "      <td>0.357613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176696</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.070743</td>\n",
       "      <td>0.339483</td>\n",
       "      <td>0.407598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.400142</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.022881</td>\n",
       "      <td>0.447320</td>\n",
       "      <td>0.127664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.183452</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.637496</td>\n",
       "      <td>0.157547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.245004</td>\n",
       "      <td>0.038117</td>\n",
       "      <td>0.396039</td>\n",
       "      <td>0.186210</td>\n",
       "      <td>0.134631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.776743</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.026041</td>\n",
       "      <td>0.174039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.828567</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.076845</td>\n",
       "      <td>0.093001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.515204</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.055616</td>\n",
       "      <td>0.359472</td>\n",
       "      <td>0.069229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Adoption      Died  Euthanasia  Return_to_owner  Transfer\n",
       "1   0.072526  0.003173    0.039508         0.191886  0.692908\n",
       "2   0.641971  0.000922    0.019447         0.258328  0.079332\n",
       "3   0.424993  0.002265    0.015572         0.199556  0.357613\n",
       "4   0.176696  0.005481    0.070743         0.339483  0.407598\n",
       "5   0.400142  0.001993    0.022881         0.447320  0.127664\n",
       "6   0.183452  0.000578    0.020927         0.637496  0.157547\n",
       "7   0.245004  0.038117    0.396039         0.186210  0.134631\n",
       "8   0.776743  0.007648    0.015528         0.026041  0.174039\n",
       "9   0.828567  0.000653    0.000934         0.076845  0.093001\n",
       "10  0.515204  0.000480    0.055616         0.359472  0.069229"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rf = pd.DataFrame(pred, columns=['Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer'])\n",
    "output_rf.index += 1\n",
    "output_rf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_rf.to_csv('submission32-xgb+rd-ensemble-voting.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
