{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valentin/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1035: UserWarning: Duplicate key in file \"/Users/valentin/anaconda/lib/python2.7/site-packages/matplotlib/mpl-data/matplotlibrc\", line #513\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "import numpy as np\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk \n",
    "\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", palette=\"muted\")\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "plt.rcParams['figure.figsize'] = 10, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('preprocessing_train_3.csv')\n",
    "df_test = pd.read_csv('preprocessing_test_3.csv')\n",
    "destinies = list(set(df_train['OutcomeType']))\n",
    "labelEncoderDestinies = preprocessing.LabelEncoder()\n",
    "labelEncoderDestinies.fit(destinies)\n",
    "#print list(df_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocesseddf = df_train\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score,log_loss\n",
    "\n",
    "\n",
    "features = list(set(df_test.columns.values).intersection(df_train.columns.values))\n",
    "\n",
    "y = preprocesseddf[\"OutcomeType\"]\n",
    "X = preprocesseddf[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OutcomeType=Adoption', 'OutcomeType=Died', 'OutcomeType=Euthanasia', 'OutcomeType=Return_to_owner', 'OutcomeType=Transfer']\n",
      "[[ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "XX = preprocesseddf[features].values\n",
    "yy = [ {'OutcomeType' : str(t)} for t in preprocesseddf['OutcomeType'].values]\n",
    "vectorizer = DV( sparse = False )\n",
    "yy = vectorizer.fit_transform(yy)\n",
    "\n",
    "print vectorizer.get_feature_names()\n",
    "#vec_x_cat_test = vectorizer.transform( x_cat_test )\n",
    "# normalization\n",
    "#XX = XX / XX.max(axis=0)\n",
    "#yy = yy / yy.max(axis=0)\n",
    "print yy\n",
    "print XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y size: 5\n",
      "X size: 313\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# define placeholderfor for images\n",
    "\n",
    "Y_size = len(set(df_train.OutcomeType))\n",
    "print \"Y size: \" + str(Y_size)\n",
    "X_size = len(features)\n",
    "print \"X size: \" + str(X_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 128 # 1st layer number of features\n",
    "n_hidden_2 = 128 # 2nd layer number of features\n",
    "n_input = XX.shape[1] # entry size (20)\n",
    "n_classes = yy.shape[1] # output size\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 4431.486581067\n",
      "Epoch: 0002 cost= 270.156248028\n",
      "Epoch: 0003 cost= 179.788091167\n",
      "Epoch: 0004 cost= 206.996633337\n",
      "Epoch: 0005 cost= 128.881551564\n",
      "Epoch: 0006 cost= 99.414705962\n",
      "Epoch: 0007 cost= 99.264367443\n",
      "Epoch: 0008 cost= 99.982587093\n",
      "Epoch: 0009 cost= 89.642976661\n",
      "Epoch: 0010 cost= 75.495491456\n",
      "Epoch: 0011 cost= 63.792800908\n",
      "Epoch: 0012 cost= 73.805791887\n",
      "Epoch: 0013 cost= 78.931978202\n",
      "Epoch: 0014 cost= 50.125283748\n",
      "Epoch: 0015 cost= 67.316293484\n",
      "Optimization Finished!\n",
      "Accuracy: 0.366381\n"
     ]
    }
   ],
   "source": [
    "def next_batch( X ,y ,i, N):\n",
    "    return X[i : i+N, :], y[i:i+N, :]\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(XX.shape[0]/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = next_batch(XX,yy,i,batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost)\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print \"Accuracy:\", accuracy.eval({x: XX, y: yy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
